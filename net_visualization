digraph {
	graph [size="47.55,47.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1645988845088 [label="
 (2, 10)" fillcolor=darkolivegreen1]
	1645988146160 [label=AddmmBackward0]
	1645988143952 -> 1645988146160
	1644058362640 [label="classifier.bias
 (10)" fillcolor=lightblue]
	1644058362640 -> 1645988143952
	1645988143952 [label=AccumulateGrad]
	1645988150096 -> 1645988146160
	1645988150096 [label=ViewBackward0]
	1645988318128 -> 1645988150096
	1645988318128 [label=MaxPool2DWithIndicesBackward0]
	1645988319808 -> 1645988318128
	1645988319808 [label=ReluBackward0]
	1645988323888 -> 1645988319808
	1645988323888 [label=CudnnBatchNormBackward0]
	1645988326624 -> 1645988323888
	1645988326624 [label=ConvolutionBackward0]
	1645988327536 -> 1645988326624
	1645988327536 [label=MaxPool2DWithIndicesBackward0]
	1645988327488 -> 1645988327536
	1645988327488 [label=ReluBackward0]
	1645988320144 -> 1645988327488
	1645988320144 [label=CudnnBatchNormBackward0]
	1645988328400 -> 1645988320144
	1645988328400 [label=ConvolutionBackward0]
	1645988327872 -> 1645988328400
	1645988327872 [label=ReluBackward0]
	1645988317360 -> 1645988327872
	1645988317360 [label=CudnnBatchNormBackward0]
	1645988323984 -> 1645988317360
	1645988323984 [label=ConvolutionBackward0]
	1645988317600 -> 1645988323984
	1645988317600 [label=ReluBackward0]
	1645988323504 -> 1645988317600
	1645988323504 [label=CudnnBatchNormBackward0]
	1645987535152 -> 1645988323504
	1645987535152 [label=ConvolutionBackward0]
	1645988328544 -> 1645987535152
	1645988328544 [label=MaxPool2DWithIndicesBackward0]
	1645988809168 -> 1645988328544
	1645988809168 [label=ReluBackward0]
	1645988809792 -> 1645988809168
	1645988809792 [label=CudnnBatchNormBackward0]
	1645988809696 -> 1645988809792
	1645988809696 [label=ConvolutionBackward0]
	1645988809600 -> 1645988809696
	1645988809600 [label=ReluBackward0]
	1645988809504 -> 1645988809600
	1645988809504 [label=CudnnBatchNormBackward0]
	1645988809408 -> 1645988809504
	1645988809408 [label=ConvolutionBackward0]
	1645988808928 -> 1645988809408
	1645988808928 [label=MaxPool2DWithIndicesBackward0]
	1645988808832 -> 1645988808928
	1645988808832 [label=ReluBackward0]
	1645988808736 -> 1645988808832
	1645988808736 [label=CudnnBatchNormBackward0]
	1645988808640 -> 1645988808736
	1645988808640 [label=ConvolutionBackward0]
	1645988808544 -> 1645988808640
	1645988808544 [label=ReluBackward0]
	1645988808448 -> 1645988808544
	1645988808448 [label=CudnnBatchNormBackward0]
	1645988808352 -> 1645988808448
	1645988808352 [label=ConvolutionBackward0]
	1645988808256 -> 1645988808352
	1645988808256 [label=ReluBackward0]
	1645988808160 -> 1645988808256
	1645988808160 [label=CudnnBatchNormBackward0]
	1645988808064 -> 1645988808160
	1645988808064 [label=ConvolutionBackward0]
	1645988807968 -> 1645988808064
	1645988807968 [label=MaxPool2DWithIndicesBackward0]
	1645988806720 -> 1645988807968
	1645988806720 [label=ReluBackward0]
	1645988807872 -> 1645988806720
	1645988807872 [label=CudnnBatchNormBackward0]
	1645988810032 -> 1645988807872
	1645988810032 [label=ConvolutionBackward0]
	1645988809936 -> 1645988810032
	1645988809936 [label=ReluBackward0]
	1645988806768 -> 1645988809936
	1645988806768 [label=CudnnBatchNormBackward0]
	1645988806960 -> 1645988806768
	1645988806960 [label=ConvolutionBackward0]
	1645988807152 -> 1645988806960
	1645988807152 [label=ReluBackward0]
	1645988807344 -> 1645988807152
	1645988807344 [label=CudnnBatchNormBackward0]
	1645988807536 -> 1645988807344
	1645988807536 [label=ConvolutionBackward0]
	1645988809360 -> 1645988807536
	1645988809360 [label=ReluBackward0]
	1645988809264 -> 1645988809360
	1645988809264 [label=CudnnBatchNormBackward0]
	1645988810080 -> 1645988809264
	1645988810080 [label=ConvolutionBackward0]
	1645988810176 -> 1645988810080
	1645988810176 [label=ToCopyBackward0]
	1645988810272 -> 1645988810176
	1645985254432 [label="
 (2, 1, 28, 28)" fillcolor=lightblue]
	1645985254432 -> 1645988810272
	1645988810272 [label=AccumulateGrad]
	1645988325952 -> 1645988810080
	1644350836944 [label="features.0.weight
 (64, 1, 3, 3)" fillcolor=lightblue]
	1644350836944 -> 1645988325952
	1645988325952 [label=AccumulateGrad]
	1645988315344 -> 1645988810080
	1644350837024 [label="features.0.bias
 (64)" fillcolor=lightblue]
	1644350837024 -> 1645988315344
	1645988315344 [label=AccumulateGrad]
	1645988317024 -> 1645988809264
	1644350648016 [label="features.1.weight
 (64)" fillcolor=lightblue]
	1644350648016 -> 1645988317024
	1645988317024 [label=AccumulateGrad]
	1645988323312 -> 1645988809264
	1644350837104 [label="features.1.bias
 (64)" fillcolor=lightblue]
	1644350837104 -> 1645988323312
	1645988323312 [label=AccumulateGrad]
	1645988327440 -> 1645988807536
	1644350837584 [label="features.4.weight
 (32, 64, 3, 3)" fillcolor=lightblue]
	1644350837584 -> 1645988327440
	1645988327440 [label=AccumulateGrad]
	1645988328016 -> 1645988807536
	1644350837664 [label="features.4.bias
 (32)" fillcolor=lightblue]
	1644350837664 -> 1645988328016
	1645988328016 [label=AccumulateGrad]
	1645988326192 -> 1645988807344
	1644350837744 [label="features.5.weight
 (32)" fillcolor=lightblue]
	1644350837744 -> 1645988326192
	1645988326192 [label=AccumulateGrad]
	1645988329360 -> 1645988807344
	1644350837824 [label="features.5.bias
 (32)" fillcolor=lightblue]
	1644350837824 -> 1645988329360
	1645988329360 [label=AccumulateGrad]
	1645988326816 -> 1645988806960
	1644350838304 [label="features.8.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1644350838304 -> 1645988326816
	1645988326816 [label=AccumulateGrad]
	1645988326912 -> 1645988806960
	1644350838384 [label="features.8.bias
 (32)" fillcolor=lightblue]
	1644350838384 -> 1645988326912
	1645988326912 [label=AccumulateGrad]
	1645988319856 -> 1645988806768
	1644350838464 [label="features.9.weight
 (32)" fillcolor=lightblue]
	1644350838464 -> 1645988319856
	1645988319856 [label=AccumulateGrad]
	1645988326768 -> 1645988806768
	1644350838544 [label="features.9.bias
 (32)" fillcolor=lightblue]
	1644350838544 -> 1645988326768
	1645988326768 [label=AccumulateGrad]
	1645988317840 -> 1645988810032
	1644350839024 [label="features.12.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1644350839024 -> 1645988317840
	1645988317840 [label=AccumulateGrad]
	1645988329696 -> 1645988810032
	1644350839104 [label="features.12.bias
 (32)" fillcolor=lightblue]
	1644350839104 -> 1645988329696
	1645988329696 [label=AccumulateGrad]
	1645988330464 -> 1645988807872
	1644350839184 [label="features.13.weight
 (32)" fillcolor=lightblue]
	1644350839184 -> 1645988330464
	1645988330464 [label=AccumulateGrad]
	1645988329552 -> 1645988807872
	1644350839264 [label="features.13.bias
 (32)" fillcolor=lightblue]
	1644350839264 -> 1645988329552
	1645988329552 [label=AccumulateGrad]
	1645988321968 -> 1645988808064
	1644350839744 [label="features.17.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1644350839744 -> 1645988321968
	1645988321968 [label=AccumulateGrad]
	1645988330416 -> 1645988808064
	1644350839824 [label="features.17.bias
 (32)" fillcolor=lightblue]
	1644350839824 -> 1645988330416
	1645988330416 [label=AccumulateGrad]
	1645988317312 -> 1645988808160
	1644350839904 [label="features.18.weight
 (32)" fillcolor=lightblue]
	1644350839904 -> 1645988317312
	1645988317312 [label=AccumulateGrad]
	1645988316976 -> 1645988808160
	1644350839984 [label="features.18.bias
 (32)" fillcolor=lightblue]
	1644350839984 -> 1645988316976
	1645988316976 [label=AccumulateGrad]
	1645988316352 -> 1645988808352
	1644350840464 [label="features.21.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1644350840464 -> 1645988316352
	1645988316352 [label=AccumulateGrad]
	1645988320336 -> 1645988808352
	1644350840544 [label="features.21.bias
 (32)" fillcolor=lightblue]
	1644350840544 -> 1645988320336
	1645988320336 [label=AccumulateGrad]
	1645988318176 -> 1645988808448
	1644350840624 [label="features.22.weight
 (32)" fillcolor=lightblue]
	1644350840624 -> 1645988318176
	1645988318176 [label=AccumulateGrad]
	1645988330368 -> 1645988808448
	1644350840704 [label="features.22.bias
 (32)" fillcolor=lightblue]
	1644350840704 -> 1645988330368
	1645988330368 [label=AccumulateGrad]
	1645988326240 -> 1645988808640
	1644350841184 [label="features.25.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	1644350841184 -> 1645988326240
	1645988326240 [label=AccumulateGrad]
	1645988315728 -> 1645988808640
	1644350841264 [label="features.25.bias
 (64)" fillcolor=lightblue]
	1644350841264 -> 1645988315728
	1645988315728 [label=AccumulateGrad]
	1645988319664 -> 1645988808736
	1644350841344 [label="features.26.weight
 (64)" fillcolor=lightblue]
	1644350841344 -> 1645988319664
	1645988319664 [label=AccumulateGrad]
	1645988317504 -> 1645988808736
	1644350841424 [label="features.26.bias
 (64)" fillcolor=lightblue]
	1644350841424 -> 1645988317504
	1645988317504 [label=AccumulateGrad]
	1645988322880 -> 1645988809408
	1644350841904 [label="features.30.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1644350841904 -> 1645988322880
	1645988322880 [label=AccumulateGrad]
	1645988322688 -> 1645988809408
	1644350841984 [label="features.30.bias
 (64)" fillcolor=lightblue]
	1644350841984 -> 1645988322688
	1645988322688 [label=AccumulateGrad]
	1645988317072 -> 1645988809504
	1644350842064 [label="features.31.weight
 (64)" fillcolor=lightblue]
	1644350842064 -> 1645988317072
	1645988317072 [label=AccumulateGrad]
	1645988322496 -> 1645988809504
	1644350842144 [label="features.31.bias
 (64)" fillcolor=lightblue]
	1644350842144 -> 1645988322496
	1645988322496 [label=AccumulateGrad]
	1645988321152 -> 1645988809696
	1644350842624 [label="features.34.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1644350842624 -> 1645988321152
	1645988321152 [label=AccumulateGrad]
	1645988320432 -> 1645988809696
	1644350842704 [label="features.34.bias
 (64)" fillcolor=lightblue]
	1644350842704 -> 1645988320432
	1645988320432 [label=AccumulateGrad]
	1645988321008 -> 1645988809792
	1644350842784 [label="features.35.weight
 (64)" fillcolor=lightblue]
	1644350842784 -> 1645988321008
	1645988321008 [label=AccumulateGrad]
	1645988320912 -> 1645988809792
	1644350842864 [label="features.35.bias
 (64)" fillcolor=lightblue]
	1644350842864 -> 1645988320912
	1645988320912 [label=AccumulateGrad]
	1645988319760 -> 1645987535152
	1644350843344 [label="features.39.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	1644350843344 -> 1645988319760
	1645988319760 [label=AccumulateGrad]
	1645988320816 -> 1645987535152
	1644350843424 [label="features.39.bias
 (128)" fillcolor=lightblue]
	1644350843424 -> 1645988320816
	1645988320816 [label=AccumulateGrad]
	1645988319328 -> 1645988323504
	1644350843504 [label="features.40.weight
 (128)" fillcolor=lightblue]
	1644350843504 -> 1645988319328
	1645988319328 [label=AccumulateGrad]
	1645988325664 -> 1645988323504
	1644350843584 [label="features.40.bias
 (128)" fillcolor=lightblue]
	1644350843584 -> 1645988325664
	1645988325664 [label=AccumulateGrad]
	1645988325280 -> 1645988323984
	1644350844064 [label="features.43.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	1644350844064 -> 1645988325280
	1645988325280 [label=AccumulateGrad]
	1645988325376 -> 1645988323984
	1644350844144 [label="features.43.bias
 (256)" fillcolor=lightblue]
	1644350844144 -> 1645988325376
	1645988325376 [label=AccumulateGrad]
	1645988317648 -> 1645988317360
	1644350844224 [label="features.44.weight
 (256)" fillcolor=lightblue]
	1644350844224 -> 1645988317648
	1645988317648 [label=AccumulateGrad]
	1645988322976 -> 1645988317360
	1644350844304 [label="features.44.bias
 (256)" fillcolor=lightblue]
	1644350844304 -> 1645988322976
	1645988322976 [label=AccumulateGrad]
	1645988318992 -> 1645988328400
	1644350844784 [label="features.47.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	1644350844784 -> 1645988318992
	1645988318992 [label=AccumulateGrad]
	1645988323024 -> 1645988328400
	1644350844864 [label="features.47.bias
 (64)" fillcolor=lightblue]
	1644350844864 -> 1645988323024
	1645988323024 [label=AccumulateGrad]
	1645988315440 -> 1645988320144
	1644350844944 [label="features.48.weight
 (64)" fillcolor=lightblue]
	1644350844944 -> 1645988315440
	1645988315440 [label=AccumulateGrad]
	1645988315920 -> 1645988320144
	1644350845024 [label="features.48.bias
 (64)" fillcolor=lightblue]
	1644350845024 -> 1645988315920
	1645988315920 [label=AccumulateGrad]
	1645988328928 -> 1645988326624
	1644350845504 [label="features.52.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1644350845504 -> 1645988328928
	1645988328928 [label=AccumulateGrad]
	1645988318464 -> 1645988326624
	1644350845584 [label="features.52.bias
 (64)" fillcolor=lightblue]
	1644350845584 -> 1645988318464
	1645988318464 [label=AccumulateGrad]
	1645988145968 -> 1645988323888
	1644350845664 [label="features.53.weight
 (64)" fillcolor=lightblue]
	1644350845664 -> 1645988145968
	1645988145968 [label=AccumulateGrad]
	1645988147552 -> 1645988323888
	1644350845744 [label="features.53.bias
 (64)" fillcolor=lightblue]
	1644350845744 -> 1645988147552
	1645988147552 [label=AccumulateGrad]
	1645988327968 -> 1645988146160
	1645988327968 [label=TBackward0]
	1645988146592 -> 1645988327968
	1644350015504 [label="classifier.weight
 (10, 64)" fillcolor=lightblue]
	1644350015504 -> 1645988146592
	1645988146592 [label=AccumulateGrad]
	1645988146160 -> 1645988845088
}
